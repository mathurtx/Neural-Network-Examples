{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_iterations = 200000\n",
    "batch_size = 128\n",
    "display_size = 10\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "dropout = 0.75\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None,n_classes])\n",
    "keep_probability = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides = [1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x,ksize = [1,k,k,1], strides = [1, k, k, 1], padding='SAME')\n",
    "\n",
    "def convNet(x, weights, bias, dropout):\n",
    "    x = tf.reshape(x, shape=[-1,28,28,1])\n",
    "    #Convolution Layer 1\n",
    "    conv1 = conv2d(x, weights['w1'], bias['b1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    #Convolution Layer 2\n",
    "    conv2 = conv2d(conv1, weights['w2'], bias['b2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), bias['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), bias['out'])\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'w1': tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "    'w2': tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out':tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "bias = {\n",
    "    'b1':tf.Variable(tf.random_normal([32])),\n",
    "    'b2':tf.Variable(tf.random_normal([64])),\n",
    "    'bd1':tf.Variable(tf.random_normal([1024])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "prediction = convNet(x, weights, bias, keep_probability)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(prediction, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:1280,Minibatch loss20484.523438,Training_accuracy:0.32031\n",
      "Iter:2560,Minibatch loss7681.899414,Training_accuracy:0.59375\n",
      "Iter:3840,Minibatch loss7614.326660,Training_accuracy:0.66406\n",
      "Iter:5120,Minibatch loss6347.348633,Training_accuracy:0.75781\n",
      "Iter:6400,Minibatch loss3328.585938,Training_accuracy:0.82031\n",
      "Iter:7680,Minibatch loss3171.914551,Training_accuracy:0.82812\n",
      "Iter:8960,Minibatch loss2867.481201,Training_accuracy:0.88281\n",
      "Iter:10240,Minibatch loss1619.229736,Training_accuracy:0.86719\n",
      "Iter:11520,Minibatch loss2337.446777,Training_accuracy:0.85156\n",
      "Iter:12800,Minibatch loss2023.565552,Training_accuracy:0.90625\n",
      "Iter:14080,Minibatch loss2743.434326,Training_accuracy:0.85156\n",
      "Iter:15360,Minibatch loss2332.479248,Training_accuracy:0.89062\n",
      "Iter:16640,Minibatch loss1516.997681,Training_accuracy:0.90625\n",
      "Iter:17920,Minibatch loss2471.589355,Training_accuracy:0.89844\n",
      "Iter:19200,Minibatch loss2848.899170,Training_accuracy:0.89844\n",
      "Iter:20480,Minibatch loss1627.068604,Training_accuracy:0.89844\n",
      "Iter:21760,Minibatch loss2042.591553,Training_accuracy:0.92188\n",
      "Iter:23040,Minibatch loss1604.038818,Training_accuracy:0.92188\n",
      "Iter:24320,Minibatch loss1236.856201,Training_accuracy:0.93750\n",
      "Iter:25600,Minibatch loss1795.841675,Training_accuracy:0.89844\n",
      "Iter:26880,Minibatch loss1483.197876,Training_accuracy:0.93750\n",
      "Iter:28160,Minibatch loss788.877136,Training_accuracy:0.96094\n",
      "Iter:29440,Minibatch loss1161.592529,Training_accuracy:0.93750\n",
      "Iter:30720,Minibatch loss1043.967651,Training_accuracy:0.92969\n",
      "Iter:32000,Minibatch loss2775.916260,Training_accuracy:0.90625\n",
      "Iter:33280,Minibatch loss1050.100952,Training_accuracy:0.90625\n",
      "Iter:34560,Minibatch loss1478.356567,Training_accuracy:0.90625\n",
      "Iter:35840,Minibatch loss1270.617920,Training_accuracy:0.92188\n",
      "Iter:37120,Minibatch loss1951.182373,Training_accuracy:0.92969\n",
      "Iter:38400,Minibatch loss834.395508,Training_accuracy:0.96094\n",
      "Iter:39680,Minibatch loss1026.792236,Training_accuracy:0.91406\n",
      "Iter:40960,Minibatch loss2216.257324,Training_accuracy:0.92188\n",
      "Iter:42240,Minibatch loss574.511963,Training_accuracy:0.96875\n",
      "Iter:43520,Minibatch loss864.441528,Training_accuracy:0.92969\n",
      "Iter:44800,Minibatch loss546.179321,Training_accuracy:0.94531\n",
      "Iter:46080,Minibatch loss1673.799805,Training_accuracy:0.89844\n",
      "Iter:47360,Minibatch loss169.606720,Training_accuracy:0.96875\n",
      "Iter:48640,Minibatch loss314.782990,Training_accuracy:0.95312\n",
      "Iter:49920,Minibatch loss997.718262,Training_accuracy:0.94531\n",
      "Iter:51200,Minibatch loss857.810669,Training_accuracy:0.96094\n",
      "Iter:52480,Minibatch loss735.892029,Training_accuracy:0.92969\n",
      "Iter:53760,Minibatch loss841.063599,Training_accuracy:0.95312\n",
      "Iter:55040,Minibatch loss784.441162,Training_accuracy:0.96094\n",
      "Iter:56320,Minibatch loss846.848816,Training_accuracy:0.92188\n",
      "Iter:57600,Minibatch loss299.049835,Training_accuracy:0.93750\n",
      "Iter:58880,Minibatch loss919.692627,Training_accuracy:0.93750\n",
      "Iter:60160,Minibatch loss788.570496,Training_accuracy:0.96875\n",
      "Iter:61440,Minibatch loss423.092865,Training_accuracy:0.95312\n",
      "Iter:62720,Minibatch loss584.575562,Training_accuracy:0.92188\n",
      "Iter:64000,Minibatch loss476.879486,Training_accuracy:0.96875\n",
      "Iter:65280,Minibatch loss209.463623,Training_accuracy:0.97656\n",
      "Iter:66560,Minibatch loss658.277222,Training_accuracy:0.96875\n",
      "Iter:67840,Minibatch loss355.463013,Training_accuracy:0.94531\n",
      "Iter:69120,Minibatch loss1002.415527,Training_accuracy:0.93750\n",
      "Iter:70400,Minibatch loss1020.769104,Training_accuracy:0.96094\n",
      "Iter:71680,Minibatch loss520.236450,Training_accuracy:0.96875\n",
      "Iter:72960,Minibatch loss541.427612,Training_accuracy:0.92188\n",
      "Iter:74240,Minibatch loss228.755539,Training_accuracy:0.96875\n",
      "Iter:75520,Minibatch loss199.026093,Training_accuracy:0.96094\n",
      "Iter:76800,Minibatch loss999.612793,Training_accuracy:0.93750\n",
      "Iter:78080,Minibatch loss424.323639,Training_accuracy:0.97656\n",
      "Iter:79360,Minibatch loss301.353333,Training_accuracy:0.96094\n",
      "Iter:80640,Minibatch loss173.037354,Training_accuracy:0.96094\n",
      "Iter:81920,Minibatch loss423.188293,Training_accuracy:0.97656\n",
      "Iter:83200,Minibatch loss495.815826,Training_accuracy:0.96094\n",
      "Iter:84480,Minibatch loss140.869736,Training_accuracy:0.96094\n",
      "Iter:85760,Minibatch loss506.559570,Training_accuracy:0.95312\n",
      "Iter:87040,Minibatch loss258.081726,Training_accuracy:0.96094\n",
      "Iter:88320,Minibatch loss116.172401,Training_accuracy:0.96875\n",
      "Iter:89600,Minibatch loss714.859802,Training_accuracy:0.92969\n",
      "Iter:90880,Minibatch loss579.928467,Training_accuracy:0.92969\n",
      "Iter:92160,Minibatch loss373.570740,Training_accuracy:0.95312\n",
      "Iter:93440,Minibatch loss423.405487,Training_accuracy:0.93750\n",
      "Iter:94720,Minibatch loss566.987427,Training_accuracy:0.96875\n",
      "Iter:96000,Minibatch loss209.339294,Training_accuracy:0.98438\n",
      "Iter:97280,Minibatch loss244.941391,Training_accuracy:0.98438\n",
      "Iter:98560,Minibatch loss240.786926,Training_accuracy:0.96094\n",
      "Iter:99840,Minibatch loss528.480591,Training_accuracy:0.96094\n",
      "Iter:101120,Minibatch loss501.701599,Training_accuracy:0.95312\n",
      "Iter:102400,Minibatch loss286.135498,Training_accuracy:0.97656\n",
      "Iter:103680,Minibatch loss312.999756,Training_accuracy:0.93750\n",
      "Iter:104960,Minibatch loss563.042542,Training_accuracy:0.95312\n",
      "Iter:106240,Minibatch loss527.537842,Training_accuracy:0.93750\n",
      "Iter:107520,Minibatch loss114.442154,Training_accuracy:0.97656\n",
      "Iter:108800,Minibatch loss480.038208,Training_accuracy:0.93750\n",
      "Iter:110080,Minibatch loss597.719849,Training_accuracy:0.94531\n",
      "Iter:111360,Minibatch loss489.641907,Training_accuracy:0.96875\n",
      "Iter:112640,Minibatch loss103.972351,Training_accuracy:0.96875\n",
      "Iter:113920,Minibatch loss114.152405,Training_accuracy:0.99219\n",
      "Iter:115200,Minibatch loss95.412186,Training_accuracy:0.98438\n",
      "Iter:116480,Minibatch loss138.312119,Training_accuracy:0.96875\n",
      "Iter:117760,Minibatch loss183.031326,Training_accuracy:0.98438\n",
      "Iter:119040,Minibatch loss18.700439,Training_accuracy:0.99219\n",
      "Iter:120320,Minibatch loss128.712585,Training_accuracy:0.97656\n",
      "Iter:121600,Minibatch loss163.546585,Training_accuracy:0.97656\n",
      "Iter:122880,Minibatch loss28.514801,Training_accuracy:0.99219\n",
      "Iter:124160,Minibatch loss100.138138,Training_accuracy:0.96094\n",
      "Iter:125440,Minibatch loss0.000000,Training_accuracy:1.00000\n",
      "Iter:126720,Minibatch loss289.397095,Training_accuracy:0.96094\n",
      "Iter:128000,Minibatch loss313.545929,Training_accuracy:0.98438\n",
      "Iter:129280,Minibatch loss316.276794,Training_accuracy:0.97656\n",
      "Iter:130560,Minibatch loss191.580017,Training_accuracy:0.96094\n",
      "Iter:131840,Minibatch loss137.676270,Training_accuracy:0.99219\n",
      "Iter:133120,Minibatch loss86.774658,Training_accuracy:0.98438\n",
      "Iter:134400,Minibatch loss682.601074,Training_accuracy:0.95312\n",
      "Iter:135680,Minibatch loss230.215912,Training_accuracy:0.97656\n",
      "Iter:136960,Minibatch loss8.182358,Training_accuracy:0.98438\n",
      "Iter:138240,Minibatch loss220.342499,Training_accuracy:0.96875\n",
      "Iter:139520,Minibatch loss382.260559,Training_accuracy:0.96094\n",
      "Iter:140800,Minibatch loss267.606140,Training_accuracy:0.96875\n",
      "Iter:142080,Minibatch loss157.670593,Training_accuracy:0.95312\n",
      "Iter:143360,Minibatch loss262.006714,Training_accuracy:0.96875\n",
      "Iter:144640,Minibatch loss287.090881,Training_accuracy:0.97656\n",
      "Iter:145920,Minibatch loss247.673676,Training_accuracy:0.98438\n",
      "Iter:147200,Minibatch loss98.147308,Training_accuracy:0.97656\n",
      "Iter:148480,Minibatch loss267.005951,Training_accuracy:0.96875\n",
      "Iter:149760,Minibatch loss395.065033,Training_accuracy:0.94531\n",
      "Iter:151040,Minibatch loss391.213379,Training_accuracy:0.96094\n",
      "Iter:152320,Minibatch loss129.867706,Training_accuracy:0.98438\n",
      "Iter:153600,Minibatch loss72.459290,Training_accuracy:0.98438\n",
      "Iter:154880,Minibatch loss479.896484,Training_accuracy:0.94531\n",
      "Iter:156160,Minibatch loss78.189926,Training_accuracy:0.98438\n",
      "Iter:157440,Minibatch loss336.125641,Training_accuracy:0.97656\n",
      "Iter:158720,Minibatch loss355.815033,Training_accuracy:0.98438\n",
      "Iter:160000,Minibatch loss80.863548,Training_accuracy:0.96875\n",
      "Iter:161280,Minibatch loss223.680664,Training_accuracy:0.96875\n",
      "Iter:162560,Minibatch loss260.543182,Training_accuracy:0.97656\n",
      "Iter:163840,Minibatch loss185.183243,Training_accuracy:0.97656\n",
      "Iter:165120,Minibatch loss434.799561,Training_accuracy:0.94531\n",
      "Iter:166400,Minibatch loss177.183197,Training_accuracy:0.97656\n",
      "Iter:167680,Minibatch loss34.335388,Training_accuracy:0.98438\n",
      "Iter:168960,Minibatch loss79.667046,Training_accuracy:0.98438\n",
      "Iter:170240,Minibatch loss374.586121,Training_accuracy:0.96094\n",
      "Iter:171520,Minibatch loss87.816673,Training_accuracy:0.97656\n",
      "Iter:172800,Minibatch loss103.331085,Training_accuracy:0.98438\n",
      "Iter:174080,Minibatch loss0.000000,Training_accuracy:1.00000\n",
      "Iter:175360,Minibatch loss242.567108,Training_accuracy:0.96875\n",
      "Iter:176640,Minibatch loss244.054626,Training_accuracy:0.96094\n",
      "Iter:177920,Minibatch loss112.112000,Training_accuracy:0.99219\n",
      "Iter:179200,Minibatch loss74.089249,Training_accuracy:0.98438\n",
      "Iter:180480,Minibatch loss40.454483,Training_accuracy:0.97656\n",
      "Iter:181760,Minibatch loss125.395081,Training_accuracy:0.97656\n",
      "Iter:183040,Minibatch loss178.783585,Training_accuracy:0.97656\n",
      "Iter:184320,Minibatch loss50.183846,Training_accuracy:0.97656\n",
      "Iter:185600,Minibatch loss205.240982,Training_accuracy:0.96875\n",
      "Iter:186880,Minibatch loss0.000000,Training_accuracy:1.00000\n",
      "Iter:188160,Minibatch loss106.710625,Training_accuracy:0.97656\n",
      "Iter:189440,Minibatch loss344.276428,Training_accuracy:0.94531\n",
      "Iter:190720,Minibatch loss63.810333,Training_accuracy:0.97656\n",
      "Iter:192000,Minibatch loss0.000000,Training_accuracy:1.00000\n",
      "Iter:193280,Minibatch loss189.277191,Training_accuracy:0.96875\n",
      "Iter:194560,Minibatch loss69.417763,Training_accuracy:0.96875\n",
      "Iter:195840,Minibatch loss173.705719,Training_accuracy:0.97656\n",
      "Iter:197120,Minibatch loss23.536804,Training_accuracy:0.99219\n",
      "Iter:198400,Minibatch loss260.869995,Training_accuracy:0.96875\n",
      "Iter:199680,Minibatch loss105.939880,Training_accuracy:0.97656\n",
      "Optimization Finished\n",
      "Testing Accuracy: 0.988281\n"
     ]
    }
   ],
   "source": [
    "model = tf.initialize_all_variables()\n",
    "with tf.Session() as session:\n",
    "    session.run(model)\n",
    "    step = 1\n",
    "    while step * batch_size < training_iterations:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        session.run(optimizer, feed_dict = {x: batch_x, y: batch_y, keep_probability: dropout})\n",
    "        if step % display_size == 0:\n",
    "            loss, acc = session.run([cost, accuracy], feed_dict = {x: batch_x, y: batch_y, keep_probability : 1.})\n",
    "            print \"Iter:\" + str(step*batch_size) + \",Minibatch loss\" + \"{:.6f}\".format(loss) + \\\n",
    "            \",Training_accuracy:\" + \"{:.5f}\".format(acc)\n",
    "        step+=1\n",
    "        \n",
    "    print \"Optimization Finished\"  \n",
    "    print \"Testing Accuracy:\", \\\n",
    "        session.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      keep_probability: 1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
